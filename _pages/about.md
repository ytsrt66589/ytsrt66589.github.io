---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm Yen-Tung (Arthur) Yeh, a first-year Ph.D. student in the [Graduate Institute of Communication Engineering](https://comm.ntu.edu.tw/en/) at **National Taiwan University**. I am a member of the [Music and AI Lab](https://affige.github.io/lab.html), advised by Prof. [Yi-Hsuan Yang](https://affige.github.io/). My research aims to **augment musicians' creativity in music production**, particularly in the production workflow. I develop high-fidelity neural audio processing models that address current challenges in music production pipelines.

My research interests include: 

* Audio effect modeling 
* Audio effect timbre transfer
* Audio effect representation learning 
* Automatic mixing and mastering 

Previously, I was a research intern at [Sony AI](https://ai.sony/) under the supervision of [Junghyun (Tony) Koo](https://www.linkedin.com/in/junghyun-koo-525a31251/?originalSubdomain=kr) during autumn 2024, where our research focused on audio effect representation learning. I completed a research internship at [Positive Grid](https://www.positivegrid.com/) during spring 2024, focusing on neural amplifier modeling. Additionally, I maintain an ongoing collaboration with the [Taipei Music Center](https://www.tmc.taipei/), where I work on LLM-based music production understanding alongside my colleague [Bo-Yu Chen](https://scholar.google.com/citations?user=ydsKndkAAAAJ&hl=zh-TW&authuser=1).

Check my CV [here]( https://ytsrt66589.github.io/files/yytung_cv.pdf). 

<style>
table {
  border-collapse: collapse;
  border: none;
  background-color: transparent;
  width: 100%;
}

table td, table th {
  border: none;
  padding: 15px 20px;
  vertical-align: top;
  background-color: transparent;
  font-size: 16px;
}

table th {
  font-weight: normal;
  color: transparent;
  border-bottom: none;
  background-color: transparent;
}

table tr {
  background-color: transparent !important;
}

table tr:nth-child(even) {
  background-color: transparent !important;
}

table tr:nth-child(odd) {
  background-color: transparent !important;
}

table td:first-child {
  width: 70%;
}

table td:last-child {
  width: 30%;
  text-align: right;
}

.logo {
  width: 120px;
  height: 100px;
  object-fit: contain;
}

.pub-links {
  margin-top: 8px;
  margin-left: 0;
  padding-left: 0;
}

.pub-links a {
  margin-right: 15px;
  text-decoration: none;
  font-size: 14px;
  color: #007acc;
}

.pub-links a:hover {
  text-decoration: underline;
}
</style>

# ðŸŽ“ Education

|---|---|
| **National Taiwan University**<br>*Ph.D. in Graduate Institute of Communication Engineering*<br>Advisor: [Yi-Hsuan Yang](https://affige.github.io/) | Feb. 2025 - Present<br><img src="../images/ntu_logo.png" alt="NTU" class="logo"> |
| **National Taiwan University**<br>*M.S. in Graduate Institute of Communication Engineering*<br>Advisor: [Yi-Hsuan Yang](https://affige.github.io/) | Feb. 2024 - Dec. 2024<br><img src="../images/ntu_logo.png" alt="NTU" class="logo"> |
| **National Taiwan University**<br>*B.S. in Computer Science and Information Engineering* | Sep. 2017 - Aug. 2022<br><img src="../images/ntu_logo.png" alt="NTU" class="logo"> |

# Professional Experience

| **Positive Grid**<br>*Deep Learning Audio Intern* <br> Topic: Unified Framework for Guitar Synthesis| April. 2025 -- Now<br><img src="../images/pg_logo.png" alt="PG" class="logo"> |
| **Sony AI**<br>*Research intern*<br>Advisor: [Junghyun (Tony) Koo](https://www.linkedin.com/in/junghyun-koo-525a31251/?originalSubdomain=kr)<br> Topic: Audio Effect Representation Learning| Sep. 2024 -- Dec. 2024<br><img src="../images/sonyai_logo.png" alt="SonyAI" class="logo"> |
| **Positive Grid**<br>*Deep Learning Audio Intern* <br> Topic: DDSP Guitar Amplifier Modeling| Mar. 2024 -- Sep. 2024<br><img src="../images/pg_logo.png" alt="PG" class="logo"> |
| **Taipei Music Center**<br>*Research Scientist/Engineering Collaborator* <br>Project Leader: [Bo-Yu Chen](https://scholar.google.com/citations?user=ydsKndkAAAAJ&hl=zh-TW&authuser=1)<br> Topic: LLM-based Music Production Understanding| Oct. 2023 -- Sep. 2024<br><img src="../images/tmc_logo.svg" alt="TMC" class="logo"> |
| **National Taiwan University**<br>*Research Assistant* <br>Advisor: [Yi-Hsuan Yang](https://affige.github.io/)<br> Topic: Neural Audio Effect Modeling| Aug. 2023 -- Jan. 2024<br><img src="../images/ntu_logo.png" alt="NTU" class="logo"> |
| **Research Center for IT Innovation, Academia Sinica**<br>*Research Assistant* <br>Advisor: [Yi-Hsuan Yang](https://affige.github.io/)<br> Topic: Neural Audio Effect Modeling| Aug. 2022 - Mar.2023<br><img src="../images/sinica_logo.png" alt="SINICA" class="logo"> |

# Honors & Awards

|---------------------|------|------|
| **NSTC Graduate  Research Fellowship**<br>*[National Science and Technology Council](https://www.nstc.gov.tw/?l=en)*| 2024-2027 |
| **Telecom Industry Excellence Fellowship**<br>*[Graduate Institute of Communication Engineering, National Taiwan University](https://gice.ntu.edu.tw/en/)*| 2024-2028 |

<style>
.orange-bold {
  color: #FF6B35;
  font-weight: bold;
}
.conference-name {
  color: #17A2B8;
  font-weight: bold;
}
</style>

# Publications

## Conference Papers

* **DDSP Guitar Amp: Interpretable Guitar Amplifier Modeling**<br>***Yen-Tung Yeh***, Yu-Hua Chen, Yuan-Chiao Cheng, Jui-Te Wu, Jun-Jie Fu, Yi-Fan Yeh, and Yi-Hsuan Yang.<br>*International Conference on Acoustics, Speech and Signal Processing (<span class="conference-name">ICASSP</span>) 2025*<br><span class="orange-bold">Oral Presentation</span>
  <div class="pub-links"><a href="https://arxiv.org/abs/2408.11405">paper</a> <a href="https://ytsrt66589.github.io/ddspGuitarAmp_Demo/">demo</a> <a href="https://drive.google.com/file/d/1PyGaXccoIVbT8AigcXrRArI8bMe681ph/view?usp=drive_link">slides</a> <a href="https://drive.google.com/file/d/10FdqtkBMvDJYuA17_SeeyEuFDap9_W3h/view?usp=sharing">poster</a></div>

* **Towards Zero-Shot Amplifier Modeling: One-to-Many Amplifier Modeling via Tone Embedding Control**<br>Yu-Hua Chen, ***Yen-Tung Yeh***, Yuan-Chiao Cheng, Jui-Te Wu, Yu-Hsiang Ho, Jyh-Shing Roger Jang, and Yi-Hsuan Yang.<br>*Proceedings of the 25th International Society for Music Information Retrieval Conference (<span class="conference-name">ISMIR</span>) 2024*
  <div class="pub-links"><a href="https://arxiv.org/pdf/2407.10646">paper</a> <a href="https://ss12f32v.github.io/Guitar-Zero-Shot/">demo</a></div>

* **Hyper Recurrent Neural Network: Condition Mechanisms for Black-box Audio Effect Modeling**<br>***Yen-Tung Yeh***, Wen-Yi Hsiao, and Yi-Hsuan Yang.<br>*27th International Conference on Digital Audio Effects (<span class="conference-name">DAFx</span>) 2024*<br><span class="orange-bold">Oral Presentation</span>
  <div class="pub-links"><a href="https://arxiv.org/abs/2408.04829">paper</a> <a href="https://github.com/ytsrt66589/pyneuralfx/tree/main">code</a> <a href="https://drive.google.com/file/d/1pyWjTqctVoQFC_7Q3yyb5vyIUq0sydRr/view?usp=sharing">poster</a></div>

* **Exploiting Pre-Trained Feature Networks for Generative Adversarial Networks in Audio-Domain Loop Generation**<br>***Yen-Tung Yeh***, Bo-Yu Chen and Yi-Hsuan Yang.<br>*Proceedings of the 23rd International Society for Music Information Retrieval Conference (<span class="conference-name">ISMIR</span>) 2022*
  <div class="pub-links"><a href="https://arxiv.org/abs/2209.01751">paper</a> <a href="https://github.com/ytsrt66589/pjloop-gan">code</a></div>

* **A Benchmarking Initiative for Audio-Domain Music Generation Using the Freesound Loop Dataset**<br>Tun-Min Hung, Bo-Yu Chen, ***Yen-Tung Yeh***, and Yi-Hsuan Yang.<br>*Proceedings of the 22nd International Society for Music Information Retrieval Conference (<span class="conference-name">ISMIR</span>) 2021*
  <div class="pub-links"><a href="https://arxiv.org/abs/2108.01576">paper</a> <a href="https://github.com/allenhung1025/LoopTest">code</a></div>

## Workshop Papers & Late-Breaking Demos

* **AI TrackMate: Finally, Someone Who Will Give Your Music More Than Just 'Sounds Great!'**<br>Yi-Lin Jiang, Chia-Ho Hsiung, ***Yen-Tung Yeh***, Lu-Rong Chen, Bo-Yu Chen.<br>*<span class="conference-name">NeurIPS</span> 2024 Creativity AI Track*
  <div class="pub-links"><a href="https://arxiv.org/abs/2412.06617">paper</a> <a href="https://worzpro.github.io/aitrackmate-demo-page/">demo</a></div>

* **PyNeuralFx: A Python Package for Neural Audio Effect Modeling**<br>***Yen-Tung Yeh***, Wen-Yi Hsiao, and Yi-Hsuan Yang.<br>*<span class="conference-name">ISMIR LBD</span> 2024*
  <div class="pub-links"><a href="https://arxiv.org/abs/2408.06053">paper</a> <a href="https://github.com/ytsrt66589/pyneuralfx/tree/main">code</a> <a href="https://drive.google.com/file/d/1KBkzzeuLbPOJ7gsb94DqZ3aakJG797c8/view?usp=sharing">poster</a></div>

* **Demo of Zero-Shot Guitar Amplifier Modelling: Enhancing Modeling with Hyper Neural Networks**<br>Yu-Hua Chen, Yuan-Chiao Cheng, ***Yen-Tung Yeh***, Jui-Te Wu, Yu-Hsiang Ho, Jyh-Shing Roger Jang, and Yi-Hsuan Yang.<br>*<span class="conference-name">ISMIR LBD</span> 2024*
  <div class="pub-links"><a href="https://arxiv.org/abs/2410.04702">paper</a></div>

## Under Review

* **Towards Generalizability to Tone and Content Variations in the Transcription of Amplifier Rendered Electric Guitar Audio**<br>Yu-Hua Chen, Yuan-Chiao Cheng, ***Yen-Tung Yeh***, Jui-Te Wu, Jyh-Shing Roger Jang, Yi-Hsuan Yang.<br>*<span class="conference-name">Under Review</span>*
  <div class="pub-links"><a href="https://arxiv.org/abs/2504.07406">paper</a> <a href="https://ss12f32v.github.io/Guitar-Transcription-with-Amplifier/">demo</a></div>
